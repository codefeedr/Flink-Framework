codefeedr {

  mongo {
    url = "mongodb://localhost:27017"
    db = "codefeedr_test"
  }

  kafka {
    server {
      bootstrap.servers = "127.0.0.1:9092"
      retries = 0
    }
    consumer {
      bootstrap.servers = "127.0.0.1:9092"
      auto.offset.reset = "earliest"
      auto.commit.interval.ms = 100
    }
    # Kafka configuration specific for codefeedrs kafka connectors
    custom {
      # Number of partitions used when creating kafka topics
      # Each source in Flink can expose data from one or more partitions,
      # so keep flink's parallism divisable by this number
      partition.count = 4
    }
  }
  zookeeper {
    connectionstring = "127.0.0.1:2181"
    connectTimeout = 5
    sessionTimeout = 30

  }
  flink {
    remote {
      host = "127.0.0.1"
      port = 6123
      parallelism = 1
      jars = "target/scala-2.11/codefeedr_2.11-0.1-SNAPSHOT-tests.jar,target/scala-2.11/codefeedr_2.11-0.1-SNAPSHOT.jar,C:\\Users\\Niels\\.ivy2\\cache\\com.typesafe.scala-logging\\scala-logging_2.11\\bundles\\scala-logging_2.11-3.5.0.jar,C:\\Users\\Niels\\.ivy2\\cache\\org.apache.kafka\\kafka-clients\\jars\\kafka-clients-0.11.0.0.jar"
    }
  }

}