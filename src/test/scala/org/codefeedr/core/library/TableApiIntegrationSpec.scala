/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 */

package org.codefeedr.core.library

import org.codefeedr.core.engine.query.{Join, SubjectSource}
import org.codefeedr.core.{FullIntegrationSpec, KafkaTest}
import org.scalatest.tagobjects.Slow
import org.apache.flink.api.scala._
import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment}
import org.apache.flink.table.api.TableEnvironment
import org.apache.flink.table.api.scala._
import org.apache.flink.types.Row
import org.codefeedr.core.library.internal.kafka.sink.KafkaTableSink
import org.codefeedr.core.library.internal.kafka.source.KafkaTableSource

import scala.async.Async.{async, await}

case class TestJoinObject(id: Long, grp: Long, message: String)

case class TestJoinGroup(id: Long, name: String)


class TableApiIntegrationSpec extends FullIntegrationSpec{

  "A TableApiSink " should " Output data that can be consumed by a TableApiSource to use Flink's table api" taggedAs (Slow, KafkaTest) in {

    //Setup some TestData
    val objects = Array(
      TestJoinObject(1, 1, "Message 1"),
      TestJoinObject(2, 1, "Message 2"),
      TestJoinObject(3, 1, "Message 3"),
      TestJoinObject(4, 2, "Message 4"),
      TestJoinObject(5, 2, "Message 5"),
      TestJoinObject(6, 2, "Message 6")
    )
    val groups = Array(TestJoinGroup(1, "Group 1"),TestJoinGroup(2, "Group 2"))

    //A join query defined in scala case class tree. This should become a structure generated by Calcite in the future
    val query = Join(SubjectSource("TestJoinObject"),
      SubjectSource("TestJoinGroup"),
      Array("grp"),
      Array("id"),
      Array("id","grp", "message"),
      Array("name"),
      "groupedMessage")


    async {
      //Simulate source environment with the defined test sets
      val objectType = await(RunSourceEnvironment(objects))
      val groupType = await(RunSourceEnvironment(groups))

      //Validate that the data is actually sent and received by the kafka topic dedicated to both datasets
      assert(await(AwaitAllData(objectType)).size == 6)
      assert(await(AwaitAllData(groupType)).size == 2)

      //Execute the query environment, and obtain the typeDefinition of the result of the query
      val resultType = await(RunQueryEnvironment(query))

      //Construct Flinks tableEnvironment
      val env = StreamExecutionEnvironment.createLocalEnvironment(parallelism)
      val tableEnv = TableEnvironment.getTableEnvironment(env)
      //Register a custom implemented tableSource based on the output from the previous query
      tableEnv.registerTableSource("my_table", new KafkaTableSource(resultType, "testSource"))


      //Perform a Flink SQL Query
      val sqlResult  = tableEnv.sql("SELECT SUM(id), grp FROM my_table GROUP BY grp")
      //Write query results to a new custom kafka table sink
      sqlResult.writeToSink(KafkaTableSink("my_sum", "testSink"))
      //Run the environment with TABLE API Query
      this.runEnvironment(env)

      //Use the zookeeper subject library to obtain the subject created by the table api environment
      val mySumSubject =  await(subjectLibrary.GetSubjects().AwaitChild("my_sum").flatMap(name => subjectLibrary.GetSubject(name).GetData())).get

      //Use the obtained typedefinition to collect all results
      //Validate that the results have properly been added and grouped (thus that the Table API Query has been executed properly)
      val mySumResult = await(AwaitAllData(mySumSubject))
      //Must use casts because there is no type compile time type of the result
      assert(mySumResult.filter(o => o.row.getField(1).asInstanceOf[Long] == 1).last.row.getField(0).asInstanceOf[Long] == 1+2+3)
      assert(mySumResult.filter(o => o.row.getField(1).asInstanceOf[Long] == 2).last.row.getField(0).asInstanceOf[Long] == 4+5+6)
    }
  }
}
